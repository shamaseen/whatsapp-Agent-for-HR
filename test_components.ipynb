{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp HR Assistant - Component Testing Notebook\n",
    "\n",
    "This notebook allows you to test each component of the HR Assistant independently.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Make sure you have:\n",
    "1. Created a `.env` file with all required credentials\n",
    "2. Placed `service-account.json` in the project root\n",
    "3. Installed all dependencies: `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì GOOGLE_API_KEY: Set\n",
      "‚úì GOOGLE_APPLICATION_CREDENTIALS: ./client_secret.json\n",
      "‚úì DATABASE_URL: Set\n",
      "‚úì EVOLUTION_API_URL: https://whatsapp-evolution-api.b3zrfu.easypanel.host\n",
      "‚úì CV_FOLDER_ID: 1P2aT3zRRpPhBPDYO-nT0NOUidqMf7lTj\n",
      "‚úì SHEETS_FOLDER_ID: 1S6ueaa_kHGBc41I--Ase8LhbZBDl0Byo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify key variables are loaded\n",
    "print(\"‚úì GOOGLE_API_KEY:\", \"Set\" if os.getenv('GOOGLE_API_KEY') else \"Missing\")\n",
    "print(\"‚úì GOOGLE_APPLICATION_CREDENTIALS:\", os.getenv('GOOGLE_APPLICATION_CREDENTIALS'))\n",
    "print(\"‚úì DATABASE_URL:\", \"Set\" if os.getenv('DATABASE_URL') else \"Missing\")\n",
    "print(\"‚úì EVOLUTION_API_URL:\", os.getenv('EVOLUTION_API_URL'))\n",
    "print(\"‚úì CV_FOLDER_ID:\", os.getenv('CV_FOLDER_ID'))\n",
    "print(\"‚úì SHEETS_FOLDER_ID:\", os.getenv('SHEETS_FOLDER_ID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Google Service Account Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error connecting to Google Services: Service account info was not in the expected format, missing fields token_uri, client_email.\n"
     ]
    }
   ],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "try:\n",
    "    # Load credentials\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        os.getenv('GOOGLE_APPLICATION_CREDENTIALS'),\n",
    "        scopes=[\n",
    "            'https://www.googleapis.com/auth/drive',\n",
    "            'https://www.googleapis.com/auth/spreadsheets',\n",
    "            'https://www.googleapis.com/auth/calendar',\n",
    "            'https://www.googleapis.com/auth/gmail.send'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Test Drive API\n",
    "    drive_service = build('drive', 'v3', credentials=credentials)\n",
    "    about = drive_service.about().get(fields=\"user\").execute()\n",
    "    \n",
    "    print(\"‚úÖ Service Account Connected Successfully!\")\n",
    "    print(f\"Service Account Email: {about.get('user', {}).get('emailAddress')}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(\"‚ùå Error: service-account.json file not found!\")\n",
    "    print(f\"Looking for file at: {os.getenv('GOOGLE_APPLICATION_CREDENTIALS')}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to Google Services: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Google Drive - List Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded saved OAuth token\n",
      "‚úÖ Google Services initialized with OAuth 2.0\n",
      "‚úÖ Found 5 PDF files in folder\n",
      "‚úÖ Found 5 PDF files in CV folder:\n",
      "1. Muhammad Ghulam Jillani.pdf (ID: 1K_dK938H0Qzlk0BWLElmjXaXHdGsqqt-)\n",
      "2. Arun Tejasvi Chaganty.pdf (ID: 1YjVPro1v7Kn_92FFA-jAL3xhTH4T41a4)\n",
      "3. Maede Jalali.pdf (ID: 1MD4syHYShviywkK6YAiQtkWu-q361-8Q)\n",
      "4. Saif Zaidan.pdf (ID: 1pg7agnhUaCI5TDQ77J4b1GIHq1bsr4c5)\n",
      "5. Yunlong Jiao.pdf (ID: 1dlwN59JUGhNJ_lBNs5W0dOaHA824sB8O)\n"
     ]
    }
   ],
   "source": [
    "from config import settings\n",
    "from services.google_drive import google_services\n",
    "\n",
    "try:\n",
    "    # List CV files in the folder\n",
    "    files = google_services.list_files_in_folder(settings.CV_FOLDER_ID)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(files)} PDF files in CV folder:\")\n",
    "    for i, file in enumerate(files[:5], 1):  # Show first 5\n",
    "        print(f\"{i}. {file['name']} (ID: {file['id']})\")\n",
    "    \n",
    "    if len(files) > 5:\n",
    "        print(f\"... and {len(files) - 5} more files\")\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        print(\"‚ö†Ô∏è No PDF files found. Make sure:\")\n",
    "        print(\"  1. CV_FOLDER_ID is correct in .env\")\n",
    "        print(\"  2. Folder is shared with service account email\")\n",
    "        print(\"  3. Folder contains PDF files\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error listing files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Google Sheets - Create/Find Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found sheet: n8n_test\n",
      "‚úÖ Found existing sheet: n8n_test\n",
      "Sheet ID: 1E-quRkTKDOBuXCh4yD2tE8D8GRlVDtAeCdYobUOC-oA\n",
      "URL: https://docs.google.com/spreadsheets/d/1E-quRkTKDOBuXCh4yD2tE8D8GRlVDtAeCdYobUOC-oA/edit\n"
     ]
    }
   ],
   "source": [
    "# Test sheet creation\n",
    "test_sheet_name = \"n8n_test\"\n",
    "\n",
    "try:\n",
    "    # Search for existing sheet\n",
    "    sheet_id = google_services.search_sheet_by_name(test_sheet_name)\n",
    "    \n",
    "    if sheet_id:\n",
    "        print(f\"‚úÖ Found existing sheet: {test_sheet_name}\")\n",
    "        print(f\"Sheet ID: {sheet_id}\")\n",
    "        print(f\"URL: https://docs.google.com/spreadsheets/d/{sheet_id}/edit\")\n",
    "    else:\n",
    "        print(f\"Creating new sheet: {test_sheet_name}\")\n",
    "        sheet_id = google_services.create_sheet(test_sheet_name)\n",
    "        print(f\"‚úÖ Sheet created successfully!\")\n",
    "        print(f\"Sheet ID: {sheet_id}\")\n",
    "        print(f\"URL: https://docs.google.com/spreadsheets/d/{sheet_id}/edit\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error with Google Sheets: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test PostgreSQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PostgreSQL Connected Successfully!\n",
      "Database version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu, comp...\n",
      "‚úÖ Table 'conversation_history' exists with 0 messages\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "try:\n",
    "    engine = create_engine(settings.DATABASE_URL)\n",
    "    \n",
    "    # Test connection\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT version();\"))\n",
    "        version = result.fetchone()[0]\n",
    "        \n",
    "    print(\"‚úÖ PostgreSQL Connected Successfully!\")\n",
    "    print(f\"Database version: {version[:50]}...\")\n",
    "    \n",
    "    # Check if table exists\n",
    "    from services.memory import ConversationHistory, Session\n",
    "    session = Session()\n",
    "    count = session.query(ConversationHistory).count()\n",
    "    print(f\"‚úÖ Table 'conversation_history' exists with {count} messages\")\n",
    "    session.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå PostgreSQL Connection Error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Check DATABASE_URL format in .env\")\n",
    "    print(\"  2. Verify database is running and accessible\")\n",
    "    print(\"  3. For Supabase: Use IPv4 or pooler URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "from services.memory import ConversationMemory\n\ntry:\n    # Create a test session\n    test_session_id = \"test_session_123\"\n    memory = ConversationMemory(test_session_id)\n    \n    # Add test messages\n    memory.add_message(\"user\", \"Hello, I want to process CVs\")\n    memory.add_message(\"assistant\", \"Sure! I'll help you process the CVs.\")\n    \n    # Retrieve history\n    history = memory.get_history(limit=5)\n    \n    print(\"‚úÖ Conversation Memory Working!\")\n    print(f\"\\nRecent messages for session '{test_session_id}':\")\n    for msg in history:\n        print(f\"  [{msg['role']}]: {msg['content']}\")\n    \n    print(f\"\\nüìä Total messages retrieved: {len(history)}\")\n    \n    # Test retrieving with different limits\n    print(\"\\nTesting with limit=2:\")\n    recent = memory.get_history(limit=2)\n    print(f\"  Retrieved {len(recent)} messages (most recent)\")\n    \n    # Show session management\n    print(\"\\nüìù Session Management:\")\n    print(f\"  Session ID: {test_session_id}\")\n    print(f\"  Messages are stored in PostgreSQL database\")\n    print(f\"  Automatically ordered by timestamp (newest first)\")\n        \nexcept Exception as e:\n    print(f\"‚ùå Memory Error: {e}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversation Memory Working!\n",
      "\n",
      "Recent messages for session 'test_session_123':\n",
      "  [user]: Hello, I want to process CVs\n",
      "  [assistant]: Sure! I'll help you process the CVs.\n"
     ]
    }
   ],
   "source": [
    "from services.memory import ConversationMemory\n",
    "\n",
    "try:\n",
    "    # Create a test session\n",
    "    test_session_id = \"test_session_123\"\n",
    "    memory = ConversationMemory(test_session_id)\n",
    "    \n",
    "    # Add test messages\n",
    "    memory.add_message(\"user\", \"Hello, I want to process CVs\")\n",
    "    memory.add_message(\"assistant\", \"Sure! I'll help you process the CVs.\")\n",
    "    \n",
    "    # Retrieve history\n",
    "    history = memory.get_history(limit=5)\n",
    "    \n",
    "    print(\"‚úÖ Conversation Memory Working!\")\n",
    "    print(f\"\\nRecent messages for session '{test_session_id}':\")\n",
    "    for msg in history:\n",
    "        print(f\"  [{msg['role']}]: {msg['content']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Memory Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Google Gemini LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Google Gemini LLM Connected!\n",
      "Model: gemini-2.5-flash\n",
      "Response: Hello, I am working!\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "try:\n",
    "    # Initialize LLM\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=settings.MODEL_NAME,\n",
    "        google_api_key=settings.GOOGLE_API_KEY,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # Test with simple message\n",
    "    response = llm.invoke([HumanMessage(content=\"Say 'Hello, I am working!' in one sentence.\")])\n",
    "    \n",
    "    print(\"‚úÖ Google Gemini LLM Connected!\")\n",
    "    print(f\"Model: {settings.MODEL_NAME}\")\n",
    "    print(f\"Response: {response.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM Error: {e}\")\n",
    "    print(\"\\nCheck:\")\n",
    "    print(\"  1. GOOGLE_API_KEY is valid\")\n",
    "    print(\"  2. Gemini API is enabled in Google Cloud Console\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test CV Processing (Single File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 5 PDF files in folder\n",
      "Testing CV extraction on: Muhammad Ghulam Jillani.pdf\n",
      "\n",
      "   Download progress: 100%\n",
      "‚úÖ File downloaded successfully\n",
      "‚úÖ Extracted 19048 characters from PDF\n",
      "\n",
      "First 500 characters:\n",
      "# **Muhammad Ghulam Jillani**\n",
      "\n",
      "**[LinkedIn |  +92-321-1174167 |](https://www.linkedin.com/in/jillanisofttech/)** **[+92-321-1179584 |](https://wa.me/qr/KBJY3C6QK4RLL1)** **Jillani** **[Portfolio.com | m.g.jillani123@gmail.com |](https://mgjillanimughal.github.io/)** **[Kaggle |](https://www.kaggle.com/jillanisofttech)** **[GitHub |    Medium](https://github.com/MGJillaniMughal)**\n",
      "\n",
      "\n",
      "**Professional Summary __________________________________________________________________________________**\n",
      "\n",
      "Senior...\n",
      "\n",
      "Testing AI-powered CV analysis...\n",
      "‚úÖ CV Data Extracted Successfully!\n",
      "\n",
      "{\n",
      "  \"fileName\": \"Muhammad Ghulam Jillani.pdf\",\n",
      "  \"name\": \"Muhammad Ghulam Jillani\",\n",
      "  \"email\": \"m.g.jillani123@gmail.com\",\n",
      "  \"phone\": \"+92-321-1174167\",\n",
      "  \"skills\": \"Python, Scikit-Learn, TensorFlow, Keras, PyTorch, NLTK, Hugging Face Transformers, OpenCV, FastAPI, Flask, Streamlit, Pandas, NumPy, Matplotlib, Plotly, Seaborn, PySpark, OpenAI API, REST APIs, GraphQL, Neo4j, Docker, GitHub Actions, CI/CD Pipelines, SQL, NoSQL, Vector Databases, Pinecone, Faiss, Chroma DB, Machine Learning, Deep Learning, Generative AI, LLMs, GPT, Gemini, LLaMA, Falcon, DeepSeek, Natural Language Processing (NLP), Time Series Analysis, Model Deployment, Prompt Engineering, LangChain, RAG, LlamaIndex, LangGraph, PhiData, LangServer, AutoGen, LangSmith, AutoML, AI-Driven Process Automation, Predictive Modeling, Statistical Analysis, Big Data Technologies, Data Visualization, AWS, SageMaker, Lambda, Bedrock, EC2, Azure, Azure ML, Azure AI, App Services, GCP, Vertex AI, Cloud Functions, Heroku, MLOps, LLMOps, AIOps, Cloud Machine Learning, MLflow, Orchestration Frameworks, Agile Methodologies, Microservices Architecture, Business Analysis, Product Management, Team Leadership, Stakeholder Management, Business Intelligence, Technical writing, Effective communication, Stakeholder engagement, Team collaboration\",\n",
      "  \"experienceYears\": 0,\n",
      "  \"education\": null,\n",
      "  \"jobTitles\": \"Senior Data Scientist & Machine Learning Software Engineer (Generative AI)\",\n",
      "  \"summary\": \"Senior Data Scientist and Machine Learning Engineer specializing in Generative AI, LLMs, and Autonomous AI Systems, with a proven record of transforming SaaS and PaaS platforms through innovative enterprise AI and agentic AI solutions. Expertise includes optimizing workflows, streamlining data pipelines, and building scalable AI architectures to solve complex business challenges. Recognized as a 24x LinkedIn Top Voice and Top 100 Global Kaggle Master, demonstrating leadership in AI-driven product innovation and LLMOps strategies.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pymupdf4llm\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import re\n",
    "\n",
    "try:\n",
    "    # Get first CV file\n",
    "    files = google_services.list_files_in_folder(settings.CV_FOLDER_ID)\n",
    "    \n",
    "    if not files:\n",
    "        print(\"‚ö†Ô∏è No CV files found to test\")\n",
    "    else:\n",
    "        test_file = files[0]\n",
    "        print(f\"Testing CV extraction on: {test_file['name']}\\n\")\n",
    "        \n",
    "        # Download and extract text\n",
    "        file_data = google_services.download_file(test_file['id'])\n",
    "        pdf_stream = io.BytesIO(file_data)\n",
    "        \n",
    "        # Open PDF from BytesIO using PyMuPDF\n",
    "        pdf_document = fitz.open(stream=pdf_stream, filetype=\"pdf\")\n",
    "        \n",
    "        # Extract text using pymupdf4llm\n",
    "        text = pymupdf4llm.to_markdown(pdf_document)\n",
    "        \n",
    "        # Close the document\n",
    "        pdf_document.close()\n",
    "        \n",
    "        print(f\"‚úÖ Extracted {len(text)} characters from PDF\")\n",
    "        print(f\"\\nFirst 500 characters:\\n{text[:500]}...\\n\")\n",
    "        \n",
    "        # Test AI extraction\n",
    "        print(\"Testing AI-powered CV analysis...\")\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=settings.MODEL_NAME,\n",
    "            google_api_key=settings.GOOGLE_API_KEY,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        prompt = f\"\"\"Analyze this CV and extract the following information in JSON format:\n",
    "\n",
    "{{\n",
    "  \"fileName\": \"{test_file['name']}\",\n",
    "  \"name\": \"full name\",\n",
    "  \"email\": \"email address\",\n",
    "  \"phone\": \"phone number\",\n",
    "  \"skills\": \"comma-separated skills\",\n",
    "  \"experienceYears\": \"number of years\",\n",
    "  \"education\": \"highest education\",\n",
    "  \"jobTitles\": \"previous job titles comma-separated\",\n",
    "  \"summary\": \"brief 2-3 sentence summary\"\n",
    "}}\n",
    "\n",
    "CV Text:\n",
    "{text[:4000]}\n",
    "\n",
    "Respond with ONLY the JSON object, no other text.\"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        json_match = re.search(r'\\{.*\\}', response.content, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            cv_data = json.loads(json_match.group(0))\n",
    "            print(\"‚úÖ CV Data Extracted Successfully!\\n\")\n",
    "            print(json.dumps(cv_data, indent=2))\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Could not parse JSON from response\")\n",
    "            print(f\"Raw response: {response.content}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå CV Processing Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Evolution API (WhatsApp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WhatsApp message sent successfully!\n",
      "Result: {'key': {'remoteJid': '962778435754@s.whatsapp.net', 'fromMe': True, 'id': '3EB05E9A61786BF09E67328DD6A2982FC5CBF834'}, 'pushName': 'Voc√™', 'status': 'PENDING', 'message': {'conversation': 'ü§ñ Test message from WhatsApp HR Assistant'}, 'messageType': 'conversation', 'messageTimestamp': 1760718255, 'instanceId': '661e228e-db82-4ef1-9f91-a69158568dee', 'source': 'unknown'}\n",
      "‚ö†Ô∏è WhatsApp test is commented out to prevent accidental messages\n",
      "Evolution API URL: https://whatsapp-evolution-api.b3zrfu.easypanel.host\n",
      "Instance: Hamza shamaseen\n",
      "\n",
      "To test: Uncomment the code above and set TEST_PHONE\n"
     ]
    }
   ],
   "source": [
    "from services.whatsapp import evolution_client\n",
    "\n",
    "# WARNING: This will send a real WhatsApp message!\n",
    "# Replace with your test phone number\n",
    "TEST_PHONE = \"962778435754\"  # e.g., \"962776241974\"\n",
    "\n",
    "# Uncomment to test (will send real message)\n",
    "try:\n",
    "    result = evolution_client.send_message(\n",
    "        TEST_PHONE,\n",
    "        \"ü§ñ Test message from WhatsApp HR Assistant\"\n",
    "    )\n",
    "    print(\"‚úÖ WhatsApp message sent successfully!\")\n",
    "    print(f\"Result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå WhatsApp Error: {e}\")\n",
    "\n",
    "print(\"‚ö†Ô∏è WhatsApp test is commented out to prevent accidental messages\")\n",
    "print(f\"Evolution API URL: {settings.EVOLUTION_API_URL}\")\n",
    "print(f\"Instance: {settings.EVOLUTION_INSTANCE_NAME}\")\n",
    "print(\"\\nTo test: Uncomment the code above and set TEST_PHONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Webex Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not initialize Webex client: Webex requires either ACCESS_TOKEN or full OAuth2 implementation\n",
      "‚ö†Ô∏è Webex client not initialized\n",
      "\n",
      "To enable Webex:\n",
      "1. Get OAuth access token (see OAuth notebook)\n",
      "2. Add to .env: WEBEX_ACCESS_TOKEN=your_token\n",
      "3. Restart the kernel\n"
     ]
    }
   ],
   "source": [
    "from tools.webex_tools import webex_client\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "if webex_client:\n",
    "    print(\"‚úÖ Webex client initialized\")\n",
    "    print(\"\\nTo test meeting creation:\")\n",
    "    print(\"1. Uncomment the code below\")\n",
    "    print(\"2. Update the invitee email\")\n",
    "    print(\"3. Run the cell\\n\")\n",
    "    \n",
    "    # Uncomment to test meeting creation\n",
    "    # try:\n",
    "    #     start = (datetime.utcnow() + timedelta(hours=24)).isoformat() + \"Z\"\n",
    "    #     end = (datetime.utcnow() + timedelta(hours=25)).isoformat() + \"Z\"\n",
    "    #     \n",
    "    #     meeting = webex_client.create_meeting(\n",
    "    #         title=\"Test Interview - HR Assistant\",\n",
    "    #         start=start,\n",
    "    #         end=end,\n",
    "    #         invitees=[\"test@example.com\"]  # Replace with real email\n",
    "    #     )\n",
    "    #     \n",
    "    #     print(\"‚úÖ Webex meeting created!\")\n",
    "    #     print(f\"Meeting ID: {meeting.get('id')}\")\n",
    "    #     print(f\"Join URL: {meeting.get('webLink')}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"‚ùå Webex Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Webex client not initialized\")\n",
    "    print(\"\\nTo enable Webex:\")\n",
    "    print(\"1. Get OAuth access token (see OAuth notebook)\")\n",
    "    print(\"2. Add to .env: WEBEX_ACCESS_TOKEN=your_token\")\n",
    "    print(\"3. Restart the kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test Complete CV Processing Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.cv_tools import search_create_sheet, process_cvs\n",
    "\n",
    "try:\n",
    "    # Create/find test sheet\n",
    "    print(\"Step 1: Creating/finding Google Sheet...\")\n",
    "    result = search_create_sheet.invoke({\"sheet_name\": test_sheet_name})\n",
    "    sheet_data = json.loads(result)\n",
    "    sheet_id = sheet_data['sheet_id']\n",
    "    print(f\"‚úÖ Sheet ID: {sheet_id}\")\n",
    "    print(f\"URL: https://docs.google.com/spreadsheets/d/{sheet_id}/edit\\n\")\n",
    "    \n",
    "    # Note: Clear the sheet first to test header creation\n",
    "    print(\"Clearing existing sheet data to test header row creation...\")\n",
    "    google_services.clear_sheet(sheet_id)\n",
    "    \n",
    "    # Process CVs (this may take a while)\n",
    "    print(\"\\nStep 2: Processing CVs (this may take several minutes)...\")\n",
    "    print(\"This will now automatically add header row if sheet is empty...\")\n",
    "    result = process_cvs.invoke({\"sheet_id\": sheet_id})\n",
    "    print(f\"\\n‚úÖ {result}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Complete! Check the Google Sheet to see:\")\n",
    "    print(\"   - Header row with column names\")\n",
    "    print(\"   - Extracted CV data in organized columns\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Candidate Search/Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for candidates matching: Senior Python Developer\n",
      "\n",
      "‚úÖ Top Candidates:\n",
      "\n",
      "Rank 1: Muhammad Ghulam Jillani.pdf\n",
      "  Email: Muhammad Ghulam Jillani\n",
      "  Phone: N/A\n",
      "  Match Score: 92%\n",
      "  Reasoning: Extensive experience in Python, related libraries (Scikit-Learn, TensorFlow, Keras, etc.), and relevant technologies like REST APIs, Docker, and CI/CD. Strong focus on Data Science and ML which are highly relevant to a Senior Python Developer role, particularly if it involves backend development for ML applications. The summary lists many technologies associated with Python development and deployment.\n",
      "\n",
      "Rank 2: Arun Tejasvi Chaganty.pdf\n",
      "  Email: Arun Tejasvi Chaganty\n",
      "  Phone: N/A\n",
      "  Match Score: 88%\n",
      "  Reasoning: PhD in Computer Science and previous roles as Research Scientist and AI Lead indicate strong technical skills and experience. Proficient in Python, including PyTorch and Tensorflow, and has experience with related technologies like SQL, Bash, and Cloud Computing. The research background is a strong positive.\n",
      "\n",
      "Rank 3: Maede Jalali.pdf\n",
      "  Email: Maede Jalali\n",
      "  Phone: N/A\n",
      "  Match Score: 85%\n",
      "  Reasoning: Experience as an AI Engineer and Software Engineer, along with skills in Python and related technologies like OpenAI and LangChain, makes this candidate a strong contender. Focus on AI systems and pipelines suggests relevant experience for a Senior Python Developer role involving complex systems.\n",
      "\n",
      "Rank 4: Yunlong Jiao.pdf\n",
      "  Email: Yunlong Jiao\n",
      "  Phone: N/A\n",
      "  Match Score: 78%\n",
      "  Reasoning: Doctoral Researcher with experience in Machine Learning and Natural Language Processing. Proficient in Python and Deep Learning. While the focus is more research-oriented, the strong technical foundation and Python skills make this candidate a potential fit for a senior developer role.\n",
      "\n",
      "Rank 5: Saif Zaidan.pdf\n",
      "  Email: Saif Zaidan\n",
      "  Phone: N/A\n",
      "  Match Score: 65%\n",
      "  Reasoning: Data Science and Data Engineer Intern. Possesses relevant skills like Python, Machine Learning, and Deep Learning. While less experienced than other candidates, the foundational skills make them a potential fit, especially if the role involves some level of mentorship or junior responsibilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tools.cv_tools import search_candidates\n",
    "\n",
    "# Replace with actual job position\n",
    "JOB_POSITION = \"Senior Python Developer\"\n",
    "\n",
    "try:\n",
    "    print(f\"Searching for candidates matching: {JOB_POSITION}\\n\")\n",
    "    \n",
    "    result = search_candidates.invoke({\n",
    "        \"sheet_id\": sheet_id,\n",
    "        \"job_position\": JOB_POSITION\n",
    "    })\n",
    "    \n",
    "    candidates = json.loads(result)\n",
    "    \n",
    "    print(\"‚úÖ Top Candidates:\\n\")\n",
    "    for candidate in candidates:\n",
    "        print(f\"Rank {candidate['rank']}: {candidate['candidate_name']}\")\n",
    "        print(f\"  Email: {candidate['email']}\")\n",
    "        print(f\"  Phone: {candidate['phone']}\")\n",
    "        print(f\"  Match Score: {candidate['match_score']}%\")\n",
    "        print(f\"  Reasoning: {candidate['reasoning']}\")\n",
    "        print()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test Complete LangGraph Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not initialize Webex client: Webex requires either ACCESS_TOKEN or full OAuth2 implementation\n",
      "Initializing LangGraph agent...\n",
      "\n",
      "Testing agent with query: 'What tools do you have available?'\n",
      "\n",
      "[SystemMessage]: You are a helpful and reliable assistant for HR recruitment tasks.\n",
      "\n",
      "## Core Rules\n",
      "\n",
      "1. **Tool Verification**: Before ANY operation, verify required tools are available\n",
      "2. **Automatic Identifiers**: Use sender's phone number as sheet identifier (e.g., \"962776241974\")\n",
      "3. **Never ask for sheet names** - derive automatically from context\n",
      "4. **Confirmation**: Request approval before create/update/delete operations\n",
      "\n",
      "## CV & Sheet Management\n",
      "\n",
      "**Sheet Naming**: ALWAYS use sender's phone number as the sheet name\n",
      "- Example: If sender is +962 77 624 1974, sheet name is \"962776241974\"\n",
      "- Never ask \"What is the sheet name?\" - extract from sender info automatically\n",
      "\n",
      "**Workflow**:\n",
      "1. Extract sender's phone number from context\n",
      "2. Call `search_create_sheet(sheet_name=phone_number)`\n",
      "3. Use returned `sheet_id` for all subsequent operations\n",
      "4. Call `process_cvs(sheet_id=sheet_id)` to analyze CVs\n",
      "5. Call `search_candidates(sheet_id=sheet_id, job_position=position)` to find matches\n",
      "\n",
      "## Available Tools\n",
      "\n",
      "- `search_create_sheet`: Find or create Google Sheet by name (use phone number)\n",
      "- `process_cvs`: Extract and analyze CVs from Google Drive\n",
      "- `search_candidates`: Rank candidates for a job position\n",
      "- `schedule_calendar_event`: Create Google Calendar events\n",
      "- `send_email`: Send emails via Gmail\n",
      "- `get_current_datetime`: Get current date and time\n",
      "\n",
      "## Communication Style\n",
      "\n",
      "- Be polite and professional\n",
      "- Show your reasoning process\n",
      "- State tool limitations clearly\n",
      "- Confirm destructive actions\n",
      "- Focus on what you CAN do\n",
      "\n",
      "\n",
      "[HumanMessage]: What tools do you have available? List them.\n",
      "\n",
      "[AIMessage]: I have access to the following tools:\n",
      "\n",
      "- `search_create_sheet`: Find or create Google Sheet by name.\n",
      "- `process_cvs`: Extract and analyze CVs from Google Drive and store in Google Sheet.\n",
      "- `search_candidates`: Search and rank candidates for a specific job position.\n",
      "- `schedule_calendar_event`: Create a Google Calendar event.\n",
      "- `send_email`: Send emails via Gmail.\n",
      "- `get_current_datetime`: Get the current date and time\n",
      "- `schedule_webex_meeting`: Create a Webex meeting.\n",
      "- `get_webex_meeting_details`: Get details of a Webex meeting.\n",
      "\n",
      "‚úÖ Agent is working!\n"
     ]
    }
   ],
   "source": [
    "from agents.hr_agent import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "try:\n",
    "    # Create agent\n",
    "    print(\"Initializing LangGraph agent...\")\n",
    "    agent_app = create_agent()\n",
    "    \n",
    "    # Test with a simple query\n",
    "    print(\"\\nTesting agent with query: 'What tools do you have available?'\\n\")\n",
    "    \n",
    "    result = agent_app.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"What tools do you have available? List them.\")],\n",
    "        \"sender_phone\": \"962776241974\",\n",
    "        \"sender_identifier\": \"test@s.whatsapp.net\"\n",
    "    })\n",
    "    \n",
    "    # Get final response\n",
    "    final_messages = result[\"messages\"]\n",
    "    for msg in final_messages:\n",
    "        if hasattr(msg, 'content') and msg.content:\n",
    "            print(f\"[{msg.__class__.__name__}]: {msg.content}\\n\")\n",
    "    \n",
    "    print(\"‚úÖ Agent is working!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Agent Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "from langchain_core.messages import HumanMessage, AIMessage\n\ntry:\n    print(\"Testing agent with conversation memory...\\n\")\n    \n    # Create memory session\n    test_user = \"962776241974@s.whatsapp.net\"\n    memory = ConversationMemory(test_user)\n    \n    # Simulate a multi-turn conversation\n    print(\"Turn 1: Initial request\")\n    print(\"-\" * 60)\n    \n    # First message\n    memory.add_message(\"user\", \"I want to process CVs\")\n    history1 = memory.get_history(limit=2)\n    \n    agent_messages = [HumanMessage(content=h['content']) if h['role'] == 'user' \n                      else AIMessage(content=h['content']) for h in history1]\n    agent_messages.append(HumanMessage(content=\"sender: 962776241974\\n\\nmessage: I want to process CVs\"))\n    \n    result1 = agent_app.invoke({\n        \"messages\": agent_messages,\n        \"sender_phone\": \"962776241974\",\n        \"sender_identifier\": test_user\n    })\n    \n    # Get response\n    for msg in reversed(result1[\"messages\"]):\n        if isinstance(msg, AIMessage) and msg.content:\n            response1 = msg.content\n            memory.add_message(\"assistant\", response1)\n            print(f\"Assistant: {response1[:200]}...\\n\")\n            break\n    \n    # Second message - referencing previous context\n    print(\"\\nTurn 2: Follow-up question (should remember context)\")\n    print(\"-\" * 60)\n    \n    memory.add_message(\"user\", \"What was my previous request?\")\n    history2 = memory.get_history(limit=4)  # Get more history\n    \n    agent_messages2 = [HumanMessage(content=h['content']) if h['role'] == 'user' \n                       else AIMessage(content=h['content']) for h in history2]\n    agent_messages2.append(HumanMessage(content=\"sender: 962776241974\\n\\nmessage: What was my previous request?\"))\n    \n    result2 = agent_app.invoke({\n        \"messages\": agent_messages2,\n        \"sender_phone\": \"962776241974\",\n        \"sender_identifier\": test_user\n    })\n    \n    # Get response\n    for msg in reversed(result2[\"messages\"]):\n        if isinstance(msg, AIMessage) and msg.content:\n            response2 = msg.content\n            print(f\"Assistant: {response2}\\n\")\n            break\n    \n    # Check if agent remembered context\n    if \"cv\" in response2.lower() or \"process\" in response2.lower():\n        print(\"‚úÖ Agent successfully remembered previous conversation!\")\n    else:\n        print(\"‚ö†Ô∏è Agent may not have used conversation history\")\n    \n    print(f\"\\nüìä Memory Stats:\")\n    print(f\"   Session: {test_user}\")\n    print(f\"   Total messages in history: {len(memory.get_history(limit=100))}\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")\n    import traceback\n    traceback.print_exc()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 13b. Test Agent with Conversation Memory\n\nTest how the agent uses memory to maintain context across messages",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n‚úÖ Components tested:\n1. Environment variables loading\n2. Google Service Account authentication\n3. Google Drive file listing\n4. Google Sheets creation/search\n5. PostgreSQL connection\n6. Conversation memory\n7. Google Gemini LLM\n8. CV text extraction\n9. Evolution API (WhatsApp)\n10. Webex integration\n11. CV processing tool\n12. Candidate search/ranking\n13. LangGraph agent\n13b. Agent with conversation memory\n14. Complete workflow\n15. **Enhanced MCP Operations** ‚≠ê NEW\n    - Gmail: get_emails, read_email, reply_email, search_emails\n    - Calendar: get_event, update_event, delete_event (Full CRUD)\n    - CV Sheet: read_all_rows, clear_sheet, search_rows\n\n## üéØ New Features: Dashboard & Logging\n\n### Real-time Monitoring Dashboard\nAccess the dashboard at: **http://localhost:8000** (or your server URL)\n\n**Features:**\n- üìä Real-time statistics (total requests, success rate, avg processing time)\n- üìã Request logs table with filters\n- üîç Detailed view of each request\n- üõ†Ô∏è Tool execution tracking\n- ü§ñ AI decision logging\n- üîÑ Auto-refresh every 10 seconds\n\n**Dashboard includes:**\n- Sender information (name, phone)\n- User messages and AI responses\n- Processing time per request\n- Tools used in each request\n- Error tracking\n- Conversation history context\n\n### API Endpoints\n\n1. `GET /` - Dashboard home page\n2. `GET /api/dashboard/stats` - Statistics\n3. `GET /api/dashboard/requests?limit=50` - Recent requests\n4. `GET /api/dashboard/request/{request_id}` - Request details\n5. `GET /api/dashboard/search?phone=&status=` - Search requests\n\n## üîß Enhanced MCP Tools (Full CRUD)\n\n### Gmail MCP - 5 Operations\n- ‚úÖ `send_email` - Send emails to candidates\n- ‚úÖ `get_emails` - Retrieve inbox emails\n- ‚úÖ `read_email` - Read specific email\n- ‚úÖ `reply_email` - Reply to threads\n- ‚úÖ `search_emails` - Search by query\n\n### Calendar MCP - 5 Operations (Complete CRUD)\n- ‚úÖ `create_event` - Schedule interviews\n- ‚úÖ `list_events` - View upcoming events\n- ‚úÖ `get_event` - Get event details\n- ‚úÖ `update_event` - Modify events\n- ‚úÖ `delete_event` - Cancel events\n\n### CV Sheet Manager - 7 Operations (Complete CRUD)\n- ‚úÖ `read_all_rows` - Get all candidates\n- ‚úÖ `append_rows` - Add candidates\n- ‚úÖ `update_row` - Modify entries\n- ‚úÖ `delete_row` - Remove entries\n- ‚úÖ `search_rows` - Query candidates\n- ‚úÖ `get_row_count` - Count entries\n- ‚úÖ `clear_sheet` - Reset sheet (keeps headers)\n\n## üìÅ MCP Organization\n\nAll tools split into separate files for easy monitoring:\n```\nmcp/\n‚îú‚îÄ‚îÄ gmail_mcp.py          # Email operations\n‚îú‚îÄ‚îÄ calendar_mcp.py       # Calendar CRUD\n‚îú‚îÄ‚îÄ cv_manager.py         # Sheet CRUD\n‚îú‚îÄ‚îÄ cv_tools_mcp.py       # CV processing\n‚îú‚îÄ‚îÄ datetime_mcp.py       # Time utilities\n‚îú‚îÄ‚îÄ webex_mcp.py          # Webex meetings\n‚îú‚îÄ‚îÄ thinking.py           # AI planning\n‚îî‚îÄ‚îÄ base.py              # Core infrastructure\n```\n\nSee **`MCP_TOOLS_OVERVIEW.md`** for complete documentation.\n\n## Next Steps\n\n1. If all tests pass, run the main application: `python main.py`\n2. Access dashboard: `http://localhost:8000`\n3. Configure your WhatsApp webhook to point to: `http://your-server:8000/webhook/whatsapp`\n4. Send test messages via WhatsApp with 'hr' label\n5. Monitor requests in real-time on the dashboard\n6. Review AI decision-making and tool usage\n7. Use enhanced MCP operations for complete recruitment workflows\n\n## Troubleshooting\n\nIf any test fails, check:\n- `.env` file has all required variables\n- `service-account.json` is in the correct location\n- Google Drive folders are shared with service account email\n- All required APIs are enabled in Google Cloud Console\n- Database is accessible and running\n- Network connectivity for external services\n- PostgreSQL tables created (request_logs, tool_execution_logs, ai_thinking_logs)\n\n## Complete Recruitment Workflow Example\n\n```python\n# 1. Get recent emails from candidates\nexecute_tool(tool_name=\"gmail\", parameters={\n    \"operation\": \"get_emails\",\n    \"max_results\": 10\n})\n\n# 2. Read specific candidate email\nexecute_tool(tool_name=\"gmail\", parameters={\n    \"operation\": \"read_email\",\n    \"message_id\": \"abc123\"\n})\n\n# 3. Process CVs\nexecute_tool(tool_name=\"process_cvs\", parameters={\n    \"sheet_id\": \"sheet123\"\n})\n\n# 4. Search qualified candidates\nexecute_tool(tool_name=\"cv_sheet_manager\", parameters={\n    \"operation\": \"search_rows\",\n    \"sheet_id\": \"sheet123\",\n    \"search_criteria\": {\"skills\": \"Python\", \"experienceYears\": \"5\"}\n})\n\n# 5. Schedule interview\nexecute_tool(tool_name=\"calendar\", parameters={\n    \"operation\": \"create_event\",\n    \"summary\": \"Interview - John Doe\",\n    \"start_time\": \"2025-10-20T14:00:00Z\",\n    \"end_time\": \"2025-10-20T15:00:00Z\",\n    \"attendees\": [\"john@example.com\"]\n})\n\n# 6. Send invitation\nexecute_tool(tool_name=\"gmail\", parameters={\n    \"operation\": \"send_email\",\n    \"to_email\": \"john@example.com\",\n    \"subject\": \"Interview Invitation\",\n    \"body\": \"Dear John, you are invited...\"\n})\n\n# 7. Reply to candidate questions\nexecute_tool(tool_name=\"gmail\", parameters={\n    \"operation\": \"reply_email\",\n    \"message_id\": \"xyz789\",\n    \"body\": \"Thank you for your question...\"\n})\n```"
  },
  {
   "cell_type": "code",
   "source": "print(\"=\"*80)\nprint(\"TEST: Enhanced CV Sheet Manager MCP Operations\")\nprint(\"=\"*80 + \"\\n\")\n\nfrom mcp.cv_manager import CVSheetManagerTool\n\ncv_manager = CVSheetManagerTool()\n\n# Use the test sheet\nif 'sheet_id' in locals():\n    print(f\"Using test sheet ID: {sheet_id}\\n\")\n    \n    # Test 1: Read all rows\n    print(\"Test 1: Read All Rows\")\n    print(\"-\" * 60)\n    try:\n        result = cv_manager.execute(\n            operation=\"read_all_rows\",\n            sheet_id=sheet_id\n        )\n        \n        result_data = json.loads(result)\n        if result_data.get(\"success\"):\n            print(f\"‚úÖ {result_data.get('message')}\")\n            print(f\"  Total candidates: {result_data.get('row_count')}\")\n            \n            candidates = result_data.get('candidates', [])\n            if candidates:\n                print(f\"\\n  First candidate:\")\n                first = candidates[0]\n                for key, value in list(first.items())[:5]:\n                    print(f\"    {key}: {value}\")\n        else:\n            print(f\"‚ö†Ô∏è Error: {result_data.get('error')}\")\n    except Exception as e:\n        print(f\"‚ùå Error: {e}\")\n    \n    # Test 2: Get row count\n    print(\"\\n\\nTest 2: Get Row Count\")\n    print(\"-\" * 60)\n    try:\n        result = cv_manager.execute(\n            operation=\"get_row_count\",\n            sheet_id=sheet_id\n        )\n        \n        result_data = json.loads(result)\n        if result_data.get(\"success\"):\n            print(f\"‚úÖ Sheet has {result_data.get('row_count')} candidates\")\n        else:\n            print(f\"‚ö†Ô∏è Error: {result_data.get('error')}\")\n    except Exception as e:\n        print(f\"‚ùå Error: {e}\")\n    \n    # Test 3: Search rows\n    print(\"\\n\\nTest 3: Search Rows\")\n    print(\"-\" * 60)\n    try:\n        result = cv_manager.execute(\n            operation=\"search_rows\",\n            sheet_id=sheet_id,\n            search_criteria={\"skills\": \"Python\"}\n        )\n        \n        result_data = json.loads(result)\n        if result_data.get(\"success\"):\n            print(f\"‚úÖ Found {result_data.get('matches')} candidates with Python skills\")\n            for candidate in result_data.get('results', [])[:3]:\n                print(f\"\\n  - {candidate.get('name', 'Unknown')}\")\n                print(f\"    Skills: {candidate.get('skills', 'N/A')[:100]}...\")\n        else:\n            print(f\"‚ö†Ô∏è Error: {result_data.get('error')}\")\n    except Exception as e:\n        print(f\"‚ùå Error: {e}\")\n    \n    # Test 4: Clear sheet (WARNING: This will delete data!)\n    print(\"\\n\\nTest 4: Clear Sheet (Optional - Commented Out)\")\n    print(\"-\" * 60)\n    print(\"‚ö†Ô∏è  To test clear_sheet, uncomment the code below:\")\n    print(\"    This will delete all candidate data but keep headers\")\n    \n    # Uncomment to test (WARNING: Deletes data!)\n    # try:\n    #     result = cv_manager.execute(\n    #         operation=\"clear_sheet\",\n    #         sheet_id=sheet_id\n    #     )\n    #     \n    #     result_data = json.loads(result)\n    #     if result_data.get(\"success\"):\n    #         print(f\"‚úÖ {result_data.get('message')}\")\n    #         print(f\"  Rows deleted: {result_data.get('rows_deleted')}\")\n    #     else:\n    #         print(f\"‚ö†Ô∏è Error: {result_data.get('error')}\")\n    # except Exception as e:\n    #     print(f\"‚ùå Error: {e}\")\n    \n    print(\"\\n‚úÖ CV Sheet Manager MCP tests completed!\")\nelse:\n    print(\"‚ö†Ô∏è No sheet_id found. Run the CV processing tests first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"=\"*80)\nprint(\"TEST: Enhanced Calendar MCP Operations\")\nprint(\"=\"*80 + \"\\n\")\n\nfrom mcp.calendar_mcp import CalendarMCPTool\nfrom datetime import datetime, timedelta\n\ncalendar_tool = CalendarMCPTool()\n\n# Test 1: List upcoming events\nprint(\"Test 1: List Upcoming Events\")\nprint(\"-\" * 60)\ntry:\n    result = calendar_tool.execute(\n        operation=\"list_events\",\n        max_results=5\n    )\n    \n    result_data = json.loads(result)\n    if result_data.get(\"success\"):\n        print(f\"‚úÖ Found {result_data.get('count', 0)} upcoming events\")\n        for event in result_data.get('events', [])[:3]:\n            print(f\"\\n  Event: {event.get('summary')}\")\n            print(f\"  Start: {event.get('start')}\")\n            print(f\"  ID: {event.get('id')}\")\n    else:\n        print(f\"‚ö†Ô∏è Error: {result_data.get('error')}\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")\n\n# Test 2: Create a test event\nprint(\"\\n\\nTest 2: Create Test Event\")\nprint(\"-\" * 60)\ntry:\n    start = (datetime.utcnow() + timedelta(days=2)).isoformat() + \"Z\"\n    end = (datetime.utcnow() + timedelta(days=2, hours=1)).isoformat() + \"Z\"\n    \n    result = calendar_tool.execute(\n        operation=\"create_event\",\n        summary=\"Test Interview - HR Assistant\",\n        start_time=start,\n        end_time=end,\n        description=\"Test event created by component tests\",\n        attendees=[]\n    )\n    \n    result_data = json.loads(result)\n    if result_data.get(\"success\"):\n        event_id = result_data.get('event_id')\n        print(f\"‚úÖ Event created successfully!\")\n        print(f\"  Event ID: {event_id}\")\n        print(f\"  Link: {result_data.get('link')}\")\n        \n        # Test 3: Get event details\n        print(\"\\n\\nTest 3: Get Event Details\")\n        print(\"-\" * 60)\n        result = calendar_tool.execute(\n            operation=\"get_event\",\n            event_id=event_id\n        )\n        \n        result_data = json.loads(result)\n        if result_data.get(\"success\"):\n            event = result_data.get('event')\n            print(f\"‚úÖ Retrieved event details\")\n            print(f\"  Summary: {event.get('summary')}\")\n            print(f\"  Status: {event.get('status')}\")\n            \n            # Test 4: Update event\n            print(\"\\n\\nTest 4: Update Event\")\n            print(\"-\" * 60)\n            result = calendar_tool.execute(\n                operation=\"update_event\",\n                event_id=event_id,\n                summary=\"Test Interview - HR Assistant (Updated)\"\n            )\n            \n            result_data = json.loads(result)\n            if result_data.get(\"success\"):\n                print(f\"‚úÖ Event updated successfully!\")\n                \n                # Test 5: Delete event\n                print(\"\\n\\nTest 5: Delete Event (Cleanup)\")\n                print(\"-\" * 60)\n                result = calendar_tool.execute(\n                    operation=\"delete_event\",\n                    event_id=event_id\n                )\n                \n                result_data = json.loads(result)\n                if result_data.get(\"success\"):\n                    print(f\"‚úÖ Event deleted successfully!\")\n                else:\n                    print(f\"‚ö†Ô∏è Delete error: {result_data.get('error')}\")\n            else:\n                print(f\"‚ö†Ô∏è Update error: {result_data.get('error')}\")\n        else:\n            print(f\"‚ö†Ô∏è Get error: {result_data.get('error')}\")\n    else:\n        print(f\"‚ö†Ô∏è Create error: {result_data.get('error')}\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")\n    import traceback\n    traceback.print_exc()\n\nprint(\"\\n‚úÖ Calendar MCP tests completed!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"=\"*80)\nprint(\"TEST: Enhanced Gmail MCP Operations\")\nprint(\"=\"*80 + \"\\n\")\n\n# Test 1: Get recent emails\nprint(\"Test 1: Get Recent Emails\")\nprint(\"-\" * 60)\ntry:\n    from mcp.gmail_mcp import GmailMCPTool\n    gmail_tool = GmailMCPTool()\n    \n    result = gmail_tool.execute(\n        operation=\"get_emails\",\n        max_results=5\n    )\n    \n    result_data = json.loads(result)\n    if result_data.get(\"success\"):\n        print(f\"‚úÖ Retrieved {result_data.get('count', 0)} emails\")\n        for email in result_data.get('emails', [])[:3]:\n            print(f\"\\n  From: {email.get('from')}\")\n            print(f\"  Subject: {email.get('subject')}\")\n            print(f\"  Date: {email.get('date')}\")\n            print(f\"  ID: {email.get('id')}\")\n    else:\n        print(f\"‚ö†Ô∏è Error: {result_data.get('error')}\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")\n\n# Test 2: Search emails\nprint(\"\\n\\nTest 2: Search Emails\")\nprint(\"-\" * 60)\ntry:\n    result = gmail_tool.execute(\n        operation=\"search_emails\",\n        query=\"subject:interview\",\n        max_results=3\n    )\n    \n    result_data = json.loads(result)\n    if result_data.get(\"success\"):\n        print(f\"‚úÖ Found {result_data.get('count', 0)} emails matching 'subject:interview'\")\n    else:\n        print(f\"‚ö†Ô∏è Error: {result_data.get('error')}\")\nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")\n\nprint(\"\\n‚úÖ Gmail MCP tests completed!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 15. Test Enhanced MCP Operations\n\nTest new operations added to Gmail, Calendar, and CV Sheet Manager",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing complete workflow...\n",
      "\n",
      "Step 1: Asking agent to process CVs\n",
      "\n",
      "‚ùå Workflow Error: name 'agent_app' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Test complete workflow: Process CVs and search for candidates\n",
    "test_phone = \"962776241974\"\n",
    "\n",
    "try:\n",
    "    print(\"Testing complete workflow...\\n\")\n",
    "    \n",
    "    # Step 1: Ask agent to process CVs\n",
    "    print(\"Step 1: Asking agent to process CVs\\n\")\n",
    "    result = agent_app.invoke({\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=f\"sender: {test_phone}\\n\\nmessage: Start process cvs\")\n",
    "        ],\n",
    "        \"sender_phone\": test_phone,\n",
    "        \"sender_identifier\": \"test@s.whatsapp.net\"\n",
    "    })\n",
    "    \n",
    "    # Print all messages\n",
    "    for msg in result[\"messages\"]:\n",
    "        if hasattr(msg, 'content') and msg.content:\n",
    "            print(f\"[{msg.__class__.__name__}]: {msg.content[:200]}...\\n\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Step 2: Ask agent to search for candidates\n",
    "    print(\"Step 2: Asking agent to search for candidates\\n\")\n",
    "    result2 = agent_app.invoke({\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=f\"sender: {test_phone}\\n\\nmessage: Find me top candidates for Senior Python Developer position\")\n",
    "        ],\n",
    "        \"sender_phone\": test_phone,\n",
    "        \"sender_identifier\": \"test@s.whatsapp.net\"\n",
    "    })\n",
    "    \n",
    "    # Print final response\n",
    "    final_msg = None\n",
    "    for msg in reversed(result2[\"messages\"]):\n",
    "        if hasattr(msg, 'content') and msg.content and msg.__class__.__name__ == \"AIMessage\":\n",
    "            final_msg = msg.content\n",
    "            break\n",
    "    \n",
    "    print(f\"Final Response:\\n{final_msg}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Complete workflow test finished!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Workflow Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ Components tested:\n",
    "1. Environment variables loading\n",
    "2. Google Service Account authentication\n",
    "3. Google Drive file listing\n",
    "4. Google Sheets creation/search\n",
    "5. PostgreSQL connection\n",
    "6. Conversation memory\n",
    "7. Google Gemini LLM\n",
    "8. CV text extraction\n",
    "9. Evolution API (WhatsApp)\n",
    "10. Webex integration\n",
    "11. CV processing tool\n",
    "12. Candidate search/ranking\n",
    "13. LangGraph agent\n",
    "14. Complete workflow\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. If all tests pass, run the main application: `python main.py`\n",
    "2. Configure your WhatsApp webhook to point to: `http://your-server:8000/webhook/whatsapp`\n",
    "3. Send test messages via WhatsApp with 'hr' label\n",
    "4. Monitor logs for any issues\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "If any test fails, check:\n",
    "- `.env` file has all required variables\n",
    "- `service-account.json` is in the correct location\n",
    "- Google Drive folders are shared with service account email\n",
    "- All required APIs are enabled in Google Cloud Console\n",
    "- Database is accessible and running\n",
    "- Network connectivity for external services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}