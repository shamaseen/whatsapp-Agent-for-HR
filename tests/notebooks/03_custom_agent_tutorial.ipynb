{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Agent Creation Tutorial\n",
    "\n",
    "This notebook teaches you how to build a custom LangGraph agent from scratch.\n",
    "\n",
    "## ðŸ“š What You'll Learn\n",
    "1. Load and configure tools\n",
    "2. Create and bind LLM with tools\n",
    "3. Define agent state and logic\n",
    "4. Build LangGraph workflow\n",
    "5. Add memory with PostgreSQL checkpointer\n",
    "6. Test your custom agent\n",
    "7. Customize agent behavior\n",
    "\n",
    "**Last Updated**: January 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('../..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(f\"âœ… Project root: {project_root}\")\n",
    "print(f\"âœ… Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Tools\n",
    "\n",
    "First, let's load the tools our agent will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.tool_factory import get_tools\n",
    "\n",
    "print(\"Step 1: Loading Tools\\n\" + \"=\"*60)\n",
    "\n",
    "# Get all available tools\n",
    "tools = get_tools()\n",
    "\n",
    "print(f\"âœ… Loaded {len(tools)} tool(s)\")\n",
    "print(\"\\nTool details:\")\n",
    "for i, tool in enumerate(tools, 1):\n",
    "    if hasattr(tool, 'name'):\n",
    "        print(f\"  {i}. {tool.name}\")\n",
    "        if hasattr(tool, 'description'):\n",
    "            print(f\"     {tool.description[:80]}...\")\n",
    "    else:\n",
    "        print(f\"  {i}. {type(tool).__name__}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Tools loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create and Configure LLM\n",
    "\n",
    "Create the LLM and bind it to our tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from config import settings\n",
    "\n",
    "print(\"Step 2: Creating LLM\\n\" + \"=\"*60)\n",
    "\n",
    "# Create the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=settings.MODEL_NAME,\n",
    "    api_key=settings.GOOGLE_API_KEY,\n",
    "    temperature=settings.TEMPERATURE\n",
    ")\n",
    "\n",
    "print(f\"âœ… LLM created\")\n",
    "print(f\"   Model: {settings.MODEL_NAME}\")\n",
    "print(f\"   Temperature: {settings.TEMPERATURE}\")\n",
    "\n",
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(f\"\\nâœ… Tools bound to LLM\")\n",
    "print(f\"   {len(tools)} tool(s) available to the agent\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… LLM configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Agent State\n",
    "\n",
    "Define the state that will be passed through the agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from typing import TypedDict\n",
    "\n",
    "print(\"Step 3: Defining Agent State\\n\" + \"=\"*60)\n",
    "\n",
    "# Define custom state extending MessagesState\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"Custom agent state with additional fields\"\"\"\n",
    "    sender_phone: str  # WhatsApp phone number\n",
    "    sender_identifier: str  # WhatsApp identifier\n",
    "\n",
    "print(\"âœ… Agent state defined\")\n",
    "print(\"\\nState fields:\")\n",
    "print(\"  â€¢ messages: List[BaseMessage] - Conversation history\")\n",
    "print(\"  â€¢ sender_phone: str - User's phone number\")\n",
    "print(\"  â€¢ sender_identifier: str - WhatsApp identifier\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… State definition complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Agent Logic\n",
    "\n",
    "Create the functions that define the agent's behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.graph import END\n",
    "from agents.prompts import SYSTEM_PROMPT\n",
    "\n",
    "print(\"Step 4: Defining Agent Logic\\n\" + \"=\"*60)\n",
    "\n",
    "# Function 1: Call the model\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"\n",
    "    Call the LLM with the current conversation state.\n",
    "    Adds system prompt if not present.\n",
    "    \"\"\"\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # Add system prompt if not present\n",
    "    if not messages or not isinstance(messages[0], SystemMessage):\n",
    "        messages = [SystemMessage(content=SYSTEM_PROMPT)] + messages\n",
    "    \n",
    "    # Call LLM\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Return new state with response\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"âœ… Defined: call_model()\")\n",
    "print(\"   Purpose: Calls LLM and returns response\")\n",
    "\n",
    "# Function 2: Decide next step\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"\n",
    "    Determine if the agent should continue or end.\n",
    "    If the last message has tool calls, route to tools.\n",
    "    Otherwise, end the conversation.\n",
    "    \"\"\"\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If there are tool calls, continue to tools\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, end\n",
    "    return END\n",
    "\n",
    "print(\"\\nâœ… Defined: should_continue()\")\n",
    "print(\"   Purpose: Routes to tools or ends conversation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Agent logic defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build LangGraph Workflow\n",
    "\n",
    "Assemble the agent graph with nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "print(\"Step 5: Building LangGraph Workflow\\n\" + \"=\"*60)\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "print(\"âœ… Graph created\\n\")\n",
    "\n",
    "# Add nodes\n",
    "print(\"Adding nodes:\")\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "print(\"  1. agent - Calls the LLM\")\n",
    "\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "print(\"  2. tools - Executes tool calls\")\n",
    "\n",
    "print(\"\\nAdding edges:\")\n",
    "\n",
    "# Entry point\n",
    "workflow.add_edge(START, \"agent\")\n",
    "print(\"  â€¢ START â†’ agent\")\n",
    "\n",
    "# Conditional edge from agent\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If tools needed, go to tools\n",
    "        END: END  # Otherwise, end\n",
    "    }\n",
    ")\n",
    "print(\"  â€¢ agent â†’ tools (if tool calls present)\")\n",
    "print(\"  â€¢ agent â†’ END (if no tool calls)\")\n",
    "\n",
    "# Loop back from tools to agent\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "print(\"  â€¢ tools â†’ agent (for next iteration)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Workflow built successfully!\")\n",
    "print(\"\\nGraph structure:\")\n",
    "print(\"  START â†’ agent â‡„ tools\")\n",
    "print(\"            â†“\")\n",
    "print(\"           END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Add Memory (Optional)\n",
    "\n",
    "Compile the graph with PostgreSQL checkpointer for conversation memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.memory_langgraph import get_checkpointer\n",
    "\n",
    "print(\"Step 6: Adding Memory\\n\" + \"=\"*60)\n",
    "\n",
    "# Option 1: Compile with memory\n",
    "print(\"Compiling with PostgreSQL checkpointer...\")\n",
    "checkpointer = get_checkpointer()\n",
    "agent_with_memory = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"âœ… Agent compiled with memory\")\n",
    "print(\"   Conversations will persist across interactions\")\n",
    "\n",
    "# Option 2: Compile without memory (uncomment if needed)\n",
    "print(\"\\nAlternatively, compile without memory:\")\n",
    "print(\"  agent_without_memory = workflow.compile()\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Memory configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Your Custom Agent\n",
    "\n",
    "Let's test the agent we just built!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"Step 7: Testing Custom Agent\\n\" + \"=\"*60)\n",
    "\n",
    "# Test 1: Simple query\n",
    "print(\"\\nTest 1: Simple query\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "query = \"Hello! What can you help me with?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "# Must provide config with thread_id for checkpointer\n",
    "config = {\"configurable\": {\"thread_id\": \"custom_test_001\"}}\n",
    "\n",
    "result = agent_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "    \"sender_phone\": \"custom_test_001\",\n",
    "    \"sender_identifier\": \"test@example.com\"\n",
    "}, config=config)\n",
    "\n",
    "print(\"Response:\")\n",
    "print(result['messages'][-1].content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Custom agent working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Query with tool\n",
    "print(\"\\nTest 2: Query requiring tool call\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "query = \"What time is it now?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"custom_test_002\"}}\n",
    "\n",
    "result = agent_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "    \"sender_phone\": \"custom_test_002\",\n",
    "    \"sender_identifier\": \"test@example.com\"\n",
    "}, config=config)\n",
    "\n",
    "print(\"Response:\")\n",
    "print(result['messages'][-1].content)\n",
    "\n",
    "print(f\"\\nTotal messages in conversation: {len(result['messages'])}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Tool calling works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Memory persistence\n",
    "print(\"\\nTest 3: Testing memory\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "thread_id = \"custom_test_003\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# First message\n",
    "print(\"First message:\")\n",
    "query1 = \"My name is Charlie.\"\n",
    "print(f\"  Query: {query1}\")\n",
    "\n",
    "result1 = agent_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=query1)],\n",
    "    \"sender_phone\": thread_id,\n",
    "    \"sender_identifier\": \"charlie@example.com\"\n",
    "}, config=config)\n",
    "\n",
    "print(f\"  Response: {result1['messages'][-1].content}\\n\")\n",
    "\n",
    "# Second message\n",
    "print(\"Second message:\")\n",
    "query2 = \"What's my name?\"\n",
    "print(f\"  Query: {query2}\")\n",
    "\n",
    "result2 = agent_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=query2)],\n",
    "    \"sender_phone\": thread_id,\n",
    "    \"sender_identifier\": \"charlie@example.com\"\n",
    "}, config=config)\n",
    "\n",
    "print(f\"  Response: {result2['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Memory persistence works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Customize Your Agent\n",
    "\n",
    "Learn how to customize the agent's behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization 1: Change System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Customization 1: Custom System Prompt\\n\" + \"=\"*60)\n",
    "\n",
    "# Define custom prompt\n",
    "CUSTOM_PROMPT = \"\"\"\n",
    "You are a friendly and enthusiastic recruiting assistant.\n",
    "Always be positive and encouraging when talking to candidates.\n",
    "Use emojis occasionally to make the conversation more engaging! ðŸ˜Š\n",
    "\n",
    "Your main tasks:\n",
    "- Help candidates with job applications\n",
    "- Schedule interviews\n",
    "- Answer questions about positions\n",
    "\"\"\"\n",
    "\n",
    "# Define new call_model function with custom prompt\n",
    "def call_model_custom(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    if not messages or not isinstance(messages[0], SystemMessage):\n",
    "        messages = [SystemMessage(content=CUSTOM_PROMPT)] + messages\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Build new workflow with custom function\n",
    "custom_workflow = StateGraph(AgentState)\n",
    "custom_workflow.add_node(\"agent\", call_model_custom)\n",
    "custom_workflow.add_node(\"tools\", ToolNode(tools))\n",
    "custom_workflow.add_edge(START, \"agent\")\n",
    "custom_workflow.add_conditional_edges(\n",
    "    \"agent\", should_continue, {\"tools\": \"tools\", END: END}\n",
    ")\n",
    "custom_workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "custom_agent = custom_workflow.compile(checkpointer=get_checkpointer())\n",
    "\n",
    "print(\"âœ… Created agent with custom system prompt\")\n",
    "print(\"\\nTest it:\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"custom_prompt_test\"}}\n",
    "result = custom_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, I'm interested in applying.\")],\n",
    "    \"sender_phone\": \"custom_prompt_test\",\n",
    "    \"sender_identifier\": \"test@example.com\"\n",
    "}, config=config)\n",
    "\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization 2: Select Specific Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCustomization 2: Specific Tools Only\\n\" + \"=\"*60)\n",
    "\n",
    "# Instead of using all tools, select specific ones\n",
    "from mcp_integration.tools.utilities.datetime_mcp import DateTimeMCPTool\n",
    "from mcp_integration.tools.google.gmail_mcp import GmailMCPTool\n",
    "\n",
    "# Create specific tools\n",
    "datetime_tool = DateTimeMCPTool()\n",
    "gmail_tool = GmailMCPTool()\n",
    "\n",
    "# Convert to LangChain tools\n",
    "specific_tools = [\n",
    "    datetime_tool.to_langchain_tool(),\n",
    "    gmail_tool.to_langchain_tool()\n",
    "]\n",
    "\n",
    "print(f\"âœ… Using {len(specific_tools)} specific tools:\")\n",
    "for tool in specific_tools:\n",
    "    print(f\"  â€¢ {tool.name}\")\n",
    "\n",
    "# Create LLM with specific tools\n",
    "llm_specific = llm.bind_tools(specific_tools)\n",
    "\n",
    "# Build workflow (similar to before, but with specific tools)\n",
    "print(\"\\nYou can now build a workflow using only these specific tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization 3: Add Custom State Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCustomization 3: Custom State Fields\\n\" + \"=\"*60)\n",
    "\n",
    "# Define extended state\n",
    "class ExtendedAgentState(MessagesState):\n",
    "    sender_phone: str\n",
    "    sender_identifier: str\n",
    "    # NEW: Custom fields\n",
    "    candidate_name: str = \"\"\n",
    "    position_applied: str = \"\"\n",
    "    interview_count: int = 0\n",
    "\n",
    "print(\"âœ… Created extended state with custom fields:\")\n",
    "print(\"  â€¢ candidate_name - Track candidate's name\")\n",
    "print(\"  â€¢ position_applied - Track position\")\n",
    "print(\"  â€¢ interview_count - Count interviews scheduled\")\n",
    "\n",
    "print(\"\\nYou can now:\")\n",
    "print(\"  1. Access these fields in your agent functions\")\n",
    "print(\"  2. Update them based on conversation\")\n",
    "print(\"  3. Use them for custom logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned how to build a custom LangGraph agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“š CUSTOM AGENT TUTORIAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\")\n",
    "\n",
    "print(\"âœ… You learned how to:\")\n",
    "print(\"  1. Load and configure tools\")\n",
    "print(\"  2. Create and bind LLM with tools\")\n",
    "print(\"  3. Define agent state and logic\")\n",
    "print(\"  4. Build LangGraph workflow (nodes + edges)\")\n",
    "print(\"  5. Add memory with PostgreSQL checkpointer\")\n",
    "print(\"  6. Test your custom agent\")\n",
    "print(\"  7. Customize agent behavior\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"ðŸ”§ Customization Options:\")\n",
    "print(\"  â€¢ System prompts - Change agent personality\")\n",
    "print(\"  â€¢ Tool selection - Choose which tools to use\")\n",
    "print(\"  â€¢ State fields - Add custom tracking fields\")\n",
    "print(\"  â€¢ Logic functions - Implement custom behaviors\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"ðŸŽ¯ Key Concepts:\")\n",
    "print(\"  â€¢ StateGraph: Defines agent workflow\")\n",
    "print(\"  â€¢ Nodes: Processing steps (agent, tools)\")\n",
    "print(\"  â€¢ Edges: Flow control between nodes\")\n",
    "print(\"  â€¢ Checkpointer: Conversation memory\")\n",
    "print(\"  â€¢ Config: Must include thread_id for memory\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸŽ‰ YOU CAN NOW BUILD CUSTOM AGENTS!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\")\n",
    "print(\"Next Steps:\")\n",
    "print(\"1. Build your own agent for a specific use case\")\n",
    "print(\"2. Experiment with different tools and prompts\")\n",
    "print(\"3. Test MCP integration: See 04_mcp_integration.ipynb\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
